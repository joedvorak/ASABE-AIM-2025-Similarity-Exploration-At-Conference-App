{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef78533",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'session_organizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msession_organizer\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Only needed if you want to reload the module after making changes\u001b[39;00m\n\u001b[32m     12\u001b[39m importlib.reload(session_organizer)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'session_organizer'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import importlib\n",
    "import session_organizer\n",
    "# Only needed if you want to reload the module after making changes\n",
    "importlib.reload(session_organizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28152da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_documents_with_genai(df_presentations, topic_column, model_name, api_key=None, df_embeddings=None, delay_seconds=1):\n",
    "    \"\"\" Embed the presentation topics using Google GenAI with rate limiting and resume capability.\n",
    "    Args:\n",
    "        df_presentations (pd.DataFrame): DataFrame containing the presentations.\n",
    "        topic_column (str): Column name in df_presentations that contains the topics to embed.\n",
    "        model_name (str): Name of the Google GenAI model to use.\n",
    "        api_key (str, optional): API key for authenticating with Google GenAI.\n",
    "        df_embeddings (pd.DataFrame, optional): DataFrame to store the embeddings. If None, a new DataFrame will be created.\n",
    "        delay_seconds (float): Delay between API calls to respect rate limits.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the embedded presentation topics.\n",
    "    \"\"\"\n",
    "    # Load environment variables\n",
    "    load_dotenv(\".env\")\n",
    "    # Check for API key in environment variables if not provided\n",
    "    if api_key is None:\n",
    "        if \"GEMINI_API_KEY\" not in os.environ:\n",
    "            raise ValueError(\n",
    "                \"API key must be provided or in environmental variables. GEMINI_API_KEY not found in environment variables. Please set it in your .env file.\"\n",
    "            )\n",
    "        else:\n",
    "            api_key = os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "    # Validate API key\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is required to use Google GenAI.\")\n",
    "\n",
    "    # Extract the topics to embed\n",
    "    topics_to_embed = df_presentations[topic_column].tolist()\n",
    "    \n",
    "    # Initialize or validate existing embeddings DataFrame\n",
    "    if df_embeddings is None:\n",
    "        df_embeddings = pd.DataFrame(columns=['topic', 'embedding', 'status'])\n",
    "    \n",
    "    # Identify which topics still need to be embedded\n",
    "    already_embedded = set(df_embeddings['topic'].tolist()) if 'topic' in df_embeddings.columns else set()\n",
    "    topics_to_process = [topic for topic in topics_to_embed if topic not in already_embedded]\n",
    "    \n",
    "    print(f\"Total topics: {len(topics_to_embed)}\")\n",
    "    print(f\"Already embedded: {len(already_embedded)}\")\n",
    "    print(f\"Topics to process: {len(topics_to_process)}\")\n",
    "    \n",
    "    # Process each topic individually\n",
    "    for i, topic in enumerate(topics_to_process):\n",
    "        print(f\"Processing topic {i+1}/{len(topics_to_process)}: {topic[:50]}...\")\n",
    "        \n",
    "        try:\n",
    "            # Call the Google GenAI API for single topic\n",
    "            response = call_google_genai_api_single(topic, model_name, api_key)\n",
    "            \n",
    "            # Process the response and add to embeddings DataFrame\n",
    "            if response and hasattr(response, 'embeddings') and response.embeddings:\n",
    "                embedding_values = response.embeddings[0].values\n",
    "                new_row = pd.DataFrame({\n",
    "                    'topic': [topic],\n",
    "                    'embedding': [embedding_values],\n",
    "                    'status': ['success']\n",
    "                })\n",
    "                df_embeddings = pd.concat([df_embeddings, new_row], ignore_index=True)\n",
    "                print(f\"Successfully embedded topic {i+1}\")\n",
    "            else:\n",
    "                # Add failed embedding to track progress\n",
    "                new_row = pd.DataFrame({\n",
    "                    'topic': [topic],\n",
    "                    'embedding': [None],\n",
    "                    'status': ['failed']\n",
    "                })\n",
    "                df_embeddings = pd.concat([df_embeddings, new_row], ignore_index=True)\n",
    "                print(f\"Failed to embed topic {i+1}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding topic {i+1}: {str(e)}\")\n",
    "            # Add error to track progress\n",
    "            new_row = pd.DataFrame({\n",
    "                'topic': [topic],\n",
    "                'embedding': [None],\n",
    "                'status': ['error']\n",
    "            })\n",
    "            df_embeddings = pd.concat([df_embeddings, new_row], ignore_index=True)\n",
    "        \n",
    "        # Rate limiting delay\n",
    "        if i < len(topics_to_process) - 1:  # Don't delay after the last item\n",
    "            time.sleep(delay_seconds)\n",
    "    \n",
    "    return df_embeddings\n",
    "\n",
    "def call_google_genai_api_single(topic, model_name, api_key):\n",
    "    \"\"\" Call the Google GenAI API to embed a single topic.\n",
    "    Args:\n",
    "        topic (str): Single topic to embed.\n",
    "        model_name (str): Name of the Google GenAI model to use.\n",
    "        api_key (str): API key for authenticating with Google GenAI.\n",
    "    Returns:\n",
    "        response: The response from the Google GenAI API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        \n",
    "        result = client.models.embed_content(\n",
    "            model=model_name,\n",
    "            contents=[topic],  # Single topic in a list\n",
    "            config=types.EmbedContentConfig(task_type=\"SEMANTIC_SIMILARITY\")\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"API call failed for topic: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def save_embeddings_to_file(df_embeddings, filename=\"embeddings_backup.pkl\"):\n",
    "    \"\"\" Save embeddings DataFrame to a pickle file for backup/resume capability.\n",
    "    Args:\n",
    "        df_embeddings (pd.DataFrame): DataFrame containing embeddings.\n",
    "        filename (str): Name of the backup file.\n",
    "    \"\"\"\n",
    "    df_embeddings.to_pickle(filename)\n",
    "    print(f\"Embeddings saved to {filename}\")\n",
    "\n",
    "def load_embeddings_from_file(filename=\"embeddings_backup.pkl\"):\n",
    "    \"\"\" Load embeddings DataFrame from a pickle file.\n",
    "    Args:\n",
    "        filename (str): Name of the backup file.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing embeddings, or None if file doesn't exist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_embeddings = pd.read_pickle(filename)\n",
    "        print(f\"Embeddings loaded from {filename}\")\n",
    "        return df_embeddings\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Backup file {filename} not found. Starting fresh.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading backup file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage with resume capability\n",
    "def embed_with_resume(df_presentations, topic_column, model_name, backup_filename=\"embeddings_backup.pkl\"):\n",
    "    \"\"\" Embed documents with automatic backup and resume capability.\n",
    "    Args:\n",
    "        df_presentations (pd.DataFrame): DataFrame containing the presentations.\n",
    "        topic_column (str): Column name containing topics to embed.\n",
    "        model_name (str): Name of the Google GenAI model to use.\n",
    "        backup_filename (str): Name of the backup file.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the embedded presentation topics.\n",
    "    \"\"\"\n",
    "    # Try to load existing embeddings\n",
    "    df_embeddings = load_embeddings_from_file(backup_filename)\n",
    "    \n",
    "    # Embed documents\n",
    "    df_embeddings = embed_documents_with_genai(\n",
    "        df_presentations=df_presentations,\n",
    "        topic_column=topic_column,\n",
    "        model_name=model_name,\n",
    "        df_embeddings=df_embeddings,\n",
    "        delay_seconds=1  # Adjust delay as needed for rate limits\n",
    "    )\n",
    "    \n",
    "    # Save backup\n",
    "    save_embeddings_to_file(df_embeddings, backup_filename)\n",
    "    \n",
    "    return df_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "985ee7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "0: 7 digit ID\n",
      "1: TC\n",
      "2: session type\n",
      "3: Session 1\n",
      "4: Pres. Title\n",
      "5: Order\n",
      "6: Start time\n",
      "7: End time\n",
      "8: Pres Auth FN\n",
      "9: Pres Auth LN\n",
      "10: Pres Affiliation\n",
      "11: Pres Auth Location\n",
      "12: All Authors\n",
      "13: Student Pres?\n",
      "14: Unnamed: 14\n",
      "15: Unnamed: 15\n",
      "\n",
      "File contains 1121 rows and 16 columns\n",
      "\n",
      "First few rows preview:\n",
      "   7 digit ID                                 TC  session type  \\\n",
      "0     2500818  ASE-Applied Science & Engineering  Oral Session   \n",
      "1     2501347  ASE-Applied Science & Engineering  Oral Session   \n",
      "2     2501703  ASE-Applied Science & Engineering  Oral Session   \n",
      "3     2501172  ASE-Applied Science & Engineering  Oral Session   \n",
      "4     2500283  ASE-Applied Science & Engineering  Oral Session   \n",
      "\n",
      "                                           Session 1  \\\n",
      "0  101 Biomass Preprocessing and Logistics for Bi...   \n",
      "1  101 Biomass Preprocessing and Logistics for Bi...   \n",
      "2  101 Biomass Preprocessing and Logistics for Bi...   \n",
      "3  101 Biomass Preprocessing and Logistics for Bi...   \n",
      "4  101 Biomass Preprocessing and Logistics for Bi...   \n",
      "\n",
      "                                         Pres. Title  Order Start time  \\\n",
      "0  Upcycling of Agri-food Resources into Packagin...    101     9:35am   \n",
      "1  Optimizing Hydrothermal Liquefaction of Oat Hu...    102     9:50am   \n",
      "2  Production of butanol from electro-fermentatio...    103    10:05am   \n",
      "3  Turning cannabis waste into high-value product...    104    10:20am   \n",
      "4  Canola meal extract as a potential feedstock f...    106    10:45am   \n",
      "\n",
      "  End time     Pres Auth FN Pres Auth LN  \\\n",
      "0   9:50am          Malvika       Sharma   \n",
      "1  10:05am         Manpreet        Singh   \n",
      "2  10:20am          Beenish         Saba   \n",
      "3  10:35am  Pabitra Chandra          Das   \n",
      "4  11:00am          Nirpesh       Dhakal   \n",
      "\n",
      "                                    Pres Affiliation  \\\n",
      "0                               University of Guelph   \n",
      "1                         University of Saskatchewan   \n",
      "2  Department of Food Agricultural and Biological...   \n",
      "3  Department of Chemical and Biological Engineer...   \n",
      "4  Department of Chemical and Biological Engineer...   \n",
      "\n",
      "                Pres Auth Location  \\\n",
      "0          Guelph, Ontario, Canada   \n",
      "1  Saskatoon, Saskatchewan, Canada   \n",
      "2              Columbus, Ohio, USA   \n",
      "3  Saskatoon, Saskatchewan, Canada   \n",
      "4  Saskatoon, Saskatchewan, Canada   \n",
      "\n",
      "                                         All Authors Student Pres?  \\\n",
      "0  Malvika Sharma, Sophie Robertson, Lonng-Tak Li...           Yes   \n",
      "1       Manpreet Singh, Falguni Pattnaik, Ajay Dalai           Yes   \n",
      "2                       Ann Christy, Katrina Cornish            No   \n",
      "3  Pabitra Chandra Das, Ravi Patel, Amin Babaei-G...           Yes   \n",
      "4                     Nirpesh Dhakal, Bishnu Acharys           Yes   \n",
      "\n",
      "   Unnamed: 14 Unnamed: 15  \n",
      "0          NaN         NaN  \n",
      "1          NaN         NaN  \n",
      "2          NaN         NaN  \n",
      "3          NaN         NaN  \n",
      "4          NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# First, examine the Excel file structure\n",
    "# We have to use 2 files as the abstracts are not in the final sechedule file.\n",
    "file_path = \"25 AIM SESSIONS FINAL.xlsx\"\n",
    "df_temp = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Available columns:\")\n",
    "for i, col in enumerate(df_temp.columns):\n",
    "    print(f\"{i}: {col}\")\n",
    "\n",
    "print(f\"\\nFile contains {len(df_temp)} rows and {len(df_temp.columns)} columns\")\n",
    "print(\"\\nFirst few rows preview:\")\n",
    "print(df_temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cbbcc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your column selections based on the output above\n",
    "TITLE_COLUMN = 'Pres. Title'  # Update based on your file\n",
    "ID_COLUMN = '7 digit ID'  # Update based on your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed104f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_abstracts = pd.read_excel(file_path)\n",
    "Title_name='Title'\n",
    "Abstract_ID_name='Submission ID',\n",
    "\n",
    "\n",
    "# Drop any presentations that are missing an ID number or title\n",
    "df_no_abstracts = df_no_abstracts.dropna(subset=[TITLE_COLUMN, ID_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f6f03de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "0: Sub #\n",
      "1: Created Date & Time\n",
      "2: Completed Date & Time\n",
      "3: Submission Status\n",
      "4: Acceptance Status\n",
      "5: # Reviews\n",
      "6: Rating\n",
      "7: Std Dev\n",
      "8: Owner-E-mail Address\n",
      "9: Owner-First Name\n",
      "10: Owner-Last Name\n",
      "11: Owner-Company/University\n",
      "12: Owner-City\n",
      "13: Owner-State\n",
      "14: Owner-Country\n",
      "15: 7 digit ID\n",
      "16: TC\n",
      "17: Session\n",
      "18: Pres. Title\n",
      "19: Abstract \n",
      "20: Order\n",
      "21: Move to oral\n",
      "22: Paper link\n",
      "23: Pres Auth FN\n",
      "24: Pres Auth LN\n",
      "25: Pres Affiliation\n",
      "26: Pres Auth Location\n",
      "27: Pres Auth Email\n",
      "28: Edited Pres Title\n",
      "29: All Authors\n",
      "30: Student Pres?\n",
      "\n",
      "File contains 1118 rows and 31 columns\n",
      "\n",
      "First few rows preview:\n",
      "   Sub # Created Date & Time Completed Date & Time Submission Status  \\\n",
      "0      1 2025-01-22 14:12:00   2025-04-22 10:24:00          Complete   \n",
      "1      1 2025-01-17 10:41:00   2025-04-15 10:43:00          Complete   \n",
      "2      1 2025-01-22 18:00:00                   NaT        Incomplete   \n",
      "3      1 2025-01-23 00:28:00   2025-05-01 00:22:00          Complete   \n",
      "4      1 2025-01-18 03:36:00   2025-04-29 23:07:00          Complete   \n",
      "\n",
      "  Acceptance Status  # Reviews  Rating  Std Dev   Owner-E-mail Address  \\\n",
      "0           Pending          1     0.0      0.0  hannu.haapala@jamk.fi   \n",
      "1           Pending          2    39.0     21.0        ecortus@umn.edu   \n",
      "2           Pending          1    54.0      0.0   d.hofstetter@ufl.edu   \n",
      "3           Pending          1    64.0      0.0       cchoi22@wisc.edu   \n",
      "4           Pending          1    66.0      0.0  rladydgus99@snu.ac.kr   \n",
      "\n",
      "  Owner-First Name  ... Move to oral Paper link Pres Auth FN Pres Auth LN  \\\n",
      "0            Hannu  ...           No          y        Hannu      Haapala   \n",
      "1             Erin  ...           No        NaN         Erin       Cortus   \n",
      "2           Daniel  ...           No        NaN       Daniel   Hofstetter   \n",
      "3      Christopher  ...           No        NaN      Sahitha   KARAPITIYA   \n",
      "4        Yong-Hyun  ...           No        NaN    Yong-Hyun          Kim   \n",
      "\n",
      "                                    Pres Affiliation  \\\n",
      "0  Jamk University of Applied Sciences, Institute...   \n",
      "1                            University of Minnesota   \n",
      "2                              University of Florida   \n",
      "3                  University of Wisconsin - Madison   \n",
      "4                          Seoul National University   \n",
      "\n",
      "         Pres Auth Location        Pres Auth Email  \\\n",
      "0       Saarijärvi, Finland  hannu.haapala@jamk.fi   \n",
      "1       Saint Paul, MN, USA        ecortus@umn.edu   \n",
      "2      Gainesville, FL, USA   d.hofstetter@ufl.edu   \n",
      "3  Madison, WI, Dane County    karapitiya@wisc.edu   \n",
      "4               South Korea  rladydgus99@snu.ac.kr   \n",
      "\n",
      "                                   Edited Pres Title  \\\n",
      "0  Economic, Environmental, and Human Benefits of...   \n",
      "1                                                NaN   \n",
      "2  Arduino Based Data Acquisition and Control Sys...   \n",
      "3  Design and Optimization of a Precision Air Jet...   \n",
      "4  Application of a GNSS/Vision Integrated Naviga...   \n",
      "\n",
      "                                         All Authors Student Pres?  \n",
      "0  Hannu Haapala, Janne Kalmari, Konsta Sarvela, ...            No  \n",
      "1  Erin Cortus, Kevin Janni, Jessica Drewry, Morg...            No  \n",
      "2                        Daniel Hofstetter, Jude Liu            No  \n",
      "3  Sahitha KARAPITIYA, Dimuth Panditharatne, Hanw...           Yes  \n",
      "4             Chulwhan Yoon, Jungun Lee, Hak-Jin Kim           Yes  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Examine the Excel file structure for the abstracts.\n",
    "file_path = \"Abstracts 5.20.xlsx\"\n",
    "df_temp = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Available columns:\")\n",
    "for i, col in enumerate(df_temp.columns):\n",
    "    print(f\"{i}: {col}\")\n",
    "\n",
    "print(f\"\\nFile contains {len(df_temp)} rows and {len(df_temp.columns)} columns\")\n",
    "print(\"\\nFirst few rows preview:\")\n",
    "print(df_temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09325d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your column selections based on the output above\n",
    "TITLE_COLUMN = 'Pres. Title'  # Update based on your file\n",
    "ABSTRACT_COLUMN = 'Abstract '  # Update based on your file  \n",
    "ID_COLUMN = '7 digit ID'  # Update based on your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b7084c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_only_abstracts = pd.read_excel(file_path, usecols=[ABSTRACT_COLUMN, ID_COLUMN])\n",
    "# Drop any presentations that are missing an ID number or abstract\n",
    "df_only_abstracts = df_only_abstracts.dropna(subset=[ABSTRACT_COLUMN, ID_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32a32d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df_no_abstracts shape: (1121, 16)\n",
      "df_only_abstracts shape: (1118, 2)\n",
      "Final merged df_final_presentations_25 shape: (1121, 17)\n",
      "Number of presentations with abstracts: 1092\n"
     ]
    }
   ],
   "source": [
    "# Merge the abstracts from df_only_abstracts into df_no_abstracts based on ID_COLUMN\n",
    "df_final_presentations_25 = df_no_abstracts.merge(\n",
    "    df_only_abstracts, \n",
    "    on=ID_COLUMN, \n",
    "    how='left'  # Keep all rows from df_no_abstracts, add abstracts where available\n",
    ")\n",
    "\n",
    "print(f\"Original df_no_abstracts shape: {df_no_abstracts.shape}\")\n",
    "print(f\"df_only_abstracts shape: {df_only_abstracts.shape}\")\n",
    "print(f\"Final merged df_final_presentations_25 shape: {df_final_presentations_25.shape}\")\n",
    "\n",
    "# Check how many presentations now have abstracts\n",
    "abstracts_added = df_final_presentations_25[ABSTRACT_COLUMN].notna().sum()\n",
    "print(f\"Number of presentations with abstracts: {abstracts_added}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b9e6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extra columns 'Unnamed: 14', 'Unamed: 15', 'Unnamed: 16' if they exist\n",
    "extra_columns = ['Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16']\n",
    "df_final_presentations_25 = df_final_presentations_25.drop(columns=[col for col in extra_columns if col in df_final_presentations_25.columns], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64cb5312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged df_final_presentations_25 shape: (1092, 16)\n",
      "Number of presentations with abstracts: 1092\n"
     ]
    }
   ],
   "source": [
    "topic_column='Title and Abstract'\n",
    "# Drop any presentations that are missing an ID number or abstract\n",
    "df_final_presentations_25 = df_final_presentations_25.dropna(subset=[ABSTRACT_COLUMN, TITLE_COLUMN, ID_COLUMN])\n",
    "df_final_presentations_25[topic_column] = df_final_presentations_25[[TITLE_COLUMN, ABSTRACT_COLUMN]].agg(': '.join, axis=1)\n",
    "print(f\"Final merged df_final_presentations_25 shape: {df_final_presentations_25.shape}\")\n",
    "\n",
    "# Check how many presentations now have abstracts\n",
    "abstracts_added = df_final_presentations_25[ABSTRACT_COLUMN].notna().sum()\n",
    "print(f\"Number of presentations with abstracts: {abstracts_added}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "957faaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup file embeddings_backup.pkl not found. Starting fresh.\n",
      "Total topics: 1092\n",
      "Already embedded: 0\n",
      "Topics to process: 1092\n",
      "Processing topic 1/1092: Upcycling of Agri-food Resources into Packaging Ma...\n",
      "Successfully embedded topic 1\n",
      "Processing topic 2/1092: Optimizing Hydrothermal Liquefaction of Oat Hulls:...\n",
      "Successfully embedded topic 2\n",
      "Processing topic 3/1092: Production of butanol from electro-fermentation of...\n",
      "Successfully embedded topic 3\n",
      "Processing topic 4/1092: Turning cannabis waste into high-value products: C...\n",
      "Successfully embedded topic 4\n",
      "Processing topic 5/1092: Canola meal extract as a potential feedstock for m...\n",
      "Successfully embedded topic 5\n",
      "Processing topic 6/1092: Evaluating Grinding Laws for Predicting the Specif...\n",
      "Successfully embedded topic 6\n",
      "Processing topic 7/1092: Optimization and Characterization of Lignin Extrac...\n",
      "Successfully embedded topic 7\n",
      "Processing topic 8/1092: Food Waste Diversion and Anaerobic Digestion as Pi...\n",
      "Successfully embedded topic 8\n",
      "Processing topic 9/1092: An Agent-based Model to Support Household Food Was...\n",
      "Successfully embedded topic 9\n",
      "Processing topic 10/1092: A geography-adjusted approach to circular bioecono...\n",
      "Successfully embedded topic 10\n",
      "Processing topic 11/1092: Human-centric and non-extractive approaches to Cir...\n",
      "Successfully embedded topic 11\n",
      "Processing topic 12/1092: Recycling polymers to make greenhouses: Canadian f...\n",
      "Successfully embedded topic 12\n",
      "Processing topic 13/1092: Case Study: Recycling Dairy Manure Solids into Pel...\n",
      "Successfully embedded topic 13\n",
      "Processing topic 14/1092: Full-scale implementation of thermal hydrolysis pr...\n",
      "Successfully embedded topic 14\n",
      "Processing topic 15/1092: Biogas-powered cooling system for improved agricul...\n",
      "Successfully embedded topic 15\n",
      "Processing topic 16/1092: Carbon capture using a microalgae photobioreactor ...\n",
      "Successfully embedded topic 16\n",
      "Processing topic 17/1092: Scale effects on horizontal frictional pressure lo...\n",
      "Successfully embedded topic 17\n",
      "Processing topic 18/1092: Hydrophobic Deep Eutectic Solvents for Pulping App...\n",
      "Successfully embedded topic 18\n",
      "Processing topic 19/1092: Development of cellulose-based products for sustai...\n",
      "Successfully embedded topic 19\n",
      "Processing topic 20/1092: 3D printed wood‐fiber reinforced architected cellu...\n",
      "Successfully embedded topic 20\n",
      "Processing topic 21/1092: Switchable aqueous PFAS adsorption and desorption ...\n",
      "Successfully embedded topic 21\n",
      "Processing topic 22/1092: Advancements in Agrivoltaics: Autonomous LiDAR and...\n",
      "Successfully embedded topic 22\n",
      "Processing topic 23/1092: Empowering Remote Communities: Sustainable Energy ...\n",
      "Successfully embedded topic 23\n",
      "Processing topic 24/1092: Low-Temperature Gasification of Animal Wastes for ...\n",
      "Successfully embedded topic 24\n",
      "Processing topic 25/1092: Phosphoric Acid Activation of Biochar for Sustaina...\n",
      "Successfully embedded topic 25\n",
      "Processing topic 26/1092: Watt a Waste: Utilizing Hurricane Debris with Cata...\n",
      "Successfully embedded topic 26\n",
      "Processing topic 27/1092: Repurposing of low-value biomass into engineered b...\n",
      "Successfully embedded topic 27\n",
      "Processing topic 28/1092: Improving energy efficiency of agricultural produc...\n",
      "Successfully embedded topic 28\n",
      "Processing topic 29/1092: Digestate Liquid: Absorption testing and techno-ec...\n",
      "Successfully embedded topic 29\n",
      "Processing topic 30/1092: Modeling and Optimization of Pelleting Processes: ...\n"
     ]
    }
   ],
   "source": [
    "df_embeddings = embed_with_resume(df_final_presentations_25, topic_column, 'gemini-embedding-exp-03-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4046acfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to embeddings_final_presentations_25_main.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the embeddings DataFrame to a file\n",
    "df_embeddings_main = df_embeddings.copy() # Create a copy since we will do another embedding\n",
    "save_embeddings_to_file(df_embeddings_main, \"embeddings_final_presentations_25_main.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b47f6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate topics found in df_embeddings_main:\n",
      "                                                  topic  \\\n",
      "0     Upcycling of Agri-food Resources into Packagin...   \n",
      "21    Advancements in Agrivoltaics: Autonomous LiDAR...   \n",
      "25    Watt a Waste: Utilizing Hurricane Debris with ...   \n",
      "82    Machine learning-powered activatable NIR-II fl...   \n",
      "94    Nucleic Acid Sensing Analysis Based on Integra...   \n",
      "101   Attention-LSTM-Based Emulation of Expert Clima...   \n",
      "187   Watt a Waste: Utilizing Hurricane Debris with ...   \n",
      "199   Machine learning-powered activatable NIR-II fl...   \n",
      "268   Plastic Mulch Effects on Hydrological Processe...   \n",
      "384   Design and Fabrication of Ergonomic Auxiliary ...   \n",
      "407   Precision Detection of the Real-Time Health an...   \n",
      "416   Nucleic Acid Sensing Analysis Based on Integra...   \n",
      "454   High-Resolution Drone Imagery and Machine Lear...   \n",
      "566   Attention-LSTM-Based Emulation of Expert Clima...   \n",
      "765   Plastic Mulch Effects on Hydrological Processe...   \n",
      "790   Techno-Economic Assessment of Atmospheric Carb...   \n",
      "810   Precision Detection of the Real-Time Health an...   \n",
      "882   Direct Biosynthesis of Organic Solvent Precurs...   \n",
      "954   Upcycling of Agri-food Resources into Packagin...   \n",
      "970   Design and Fabrication of Ergonomic Auxiliary ...   \n",
      "975   Process engineering and modelling-enabled stra...   \n",
      "976   Process engineering and modelling-enabled stra...   \n",
      "990   Techno-Economic Assessment of Atmospheric Carb...   \n",
      "1031  Advancements in Agrivoltaics: Autonomous LiDAR...   \n",
      "1035  High-Resolution Drone Imagery and Machine Lear...   \n",
      "1081  Direct Biosynthesis of Organic Solvent Precurs...   \n",
      "\n",
      "                                              embedding  \n",
      "0     [0.006443611, -0.0047268895, 0.0004655311, -0....  \n",
      "21    [0.0005555009, 0.0013302452, 0.0009946274, -0....  \n",
      "25    [0.011110447, -0.0114809815, 0.003649761, -0.0...  \n",
      "82    [0.004265079, 0.02134478, 0.002975417, -0.0478...  \n",
      "94    [0.022740327, -0.012879503, -0.008316467, -0.0...  \n",
      "101   [-0.010537176, 0.003928131, 0.00055118225, -0....  \n",
      "187   [0.011110447, -0.0114809815, 0.003649761, -0.0...  \n",
      "199   [0.004265079, 0.02134478, 0.002975417, -0.0478...  \n",
      "268   [-0.0038002008, 0.006603062, 0.025407147, -0.0...  \n",
      "384   [0.0009478454, -0.0073851077, 0.006521874, -0....  \n",
      "407   [-0.00057108945, 0.011627258, 0.003981434, -0....  \n",
      "416   [0.022740327, -0.012879503, -0.008316467, -0.0...  \n",
      "454   [0.0067906533, -0.0023045496, -0.0032858986, -...  \n",
      "566   [-0.010537176, 0.003928131, 0.00055118225, -0....  \n",
      "765   [-0.0038002008, 0.006603062, 0.025407147, -0.0...  \n",
      "790   [0.0059995796, -0.014181335, -0.010112776, -0....  \n",
      "810   [-0.00057108945, 0.011627258, 0.003981434, -0....  \n",
      "882   [0.03314368, 0.0039059592, -0.009214216, -0.05...  \n",
      "954   [0.006443611, -0.0047268895, 0.0004655311, -0....  \n",
      "970   [0.0009478454, -0.0073851077, 0.006521874, -0....  \n",
      "975   [0.024396367, -0.01875451, 0.007905525, -0.066...  \n",
      "976   [0.024396367, -0.01875451, 0.007905525, -0.066...  \n",
      "990   [0.0059995796, -0.014181335, -0.010112776, -0....  \n",
      "1031  [0.0005555009, 0.0013302452, 0.0009946274, -0....  \n",
      "1035  [0.0067906533, -0.0023045496, -0.0032858986, -...  \n",
      "1081  [0.03314368, 0.0039059592, -0.009214216, -0.05...  \n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate topics in the embeddings DataFrame\n",
    "duplicates = df_embeddings_main[df_embeddings_main.duplicated(subset=['topic'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicate topics found in df_embeddings_main:\")\n",
    "    print(duplicates[['topic', 'embedding']])\n",
    "else:\n",
    "    print(\"No duplicate topics found in df_embeddings_main.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "03fad2c7",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings column added to df_final_presentations_25.\n"
     ]
    }
   ],
   "source": [
    "# Merge embeddings into df_final_presentations_25 based on the topic_column\n",
    "df_final_presentations_25_w_embeddings = df_final_presentations_25.merge(\n",
    "    df_embeddings_main[['topic', 'embedding']].drop_duplicates(subset=['topic']),\n",
    "    left_on=topic_column,\n",
    "    right_on='topic',\n",
    "    how='left'\n",
    ")\n",
    "print(\"Embeddings column added to df_final_presentations_25.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73861d5",
   "metadata": {},
   "source": [
    "# Duplicate Presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8abd37dd",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate topics found in df_final_presentations_25_w_embeddings:\n",
      "Number of duplicate topics: 13\n",
      "                                     Title and Abstract  \\\n",
      "0     Upcycling of Agri-food Resources into Packagin...   \n",
      "21    Advancements in Agrivoltaics: Autonomous LiDAR...   \n",
      "25    Watt a Waste: Utilizing Hurricane Debris with ...   \n",
      "82    Machine learning-powered activatable NIR-II fl...   \n",
      "94    Nucleic Acid Sensing Analysis Based on Integra...   \n",
      "101   Attention-LSTM-Based Emulation of Expert Clima...   \n",
      "187   Watt a Waste: Utilizing Hurricane Debris with ...   \n",
      "199   Machine learning-powered activatable NIR-II fl...   \n",
      "268   Plastic Mulch Effects on Hydrological Processe...   \n",
      "384   Design and Fabrication of Ergonomic Auxiliary ...   \n",
      "407   Precision Detection of the Real-Time Health an...   \n",
      "416   Nucleic Acid Sensing Analysis Based on Integra...   \n",
      "454   High-Resolution Drone Imagery and Machine Lear...   \n",
      "566   Attention-LSTM-Based Emulation of Expert Clima...   \n",
      "765   Plastic Mulch Effects on Hydrological Processe...   \n",
      "790   Techno-Economic Assessment of Atmospheric Carb...   \n",
      "810   Precision Detection of the Real-Time Health an...   \n",
      "882   Direct Biosynthesis of Organic Solvent Precurs...   \n",
      "954   Upcycling of Agri-food Resources into Packagin...   \n",
      "970   Design and Fabrication of Ergonomic Auxiliary ...   \n",
      "975   Process engineering and modelling-enabled stra...   \n",
      "976   Process engineering and modelling-enabled stra...   \n",
      "990   Techno-Economic Assessment of Atmospheric Carb...   \n",
      "1031  Advancements in Agrivoltaics: Autonomous LiDAR...   \n",
      "1035  High-Resolution Drone Imagery and Machine Lear...   \n",
      "1081  Direct Biosynthesis of Organic Solvent Precurs...   \n",
      "\n",
      "                                                  topic  \n",
      "0     Upcycling of Agri-food Resources into Packagin...  \n",
      "21    Advancements in Agrivoltaics: Autonomous LiDAR...  \n",
      "25    Watt a Waste: Utilizing Hurricane Debris with ...  \n",
      "82    Machine learning-powered activatable NIR-II fl...  \n",
      "94    Nucleic Acid Sensing Analysis Based on Integra...  \n",
      "101   Attention-LSTM-Based Emulation of Expert Clima...  \n",
      "187   Watt a Waste: Utilizing Hurricane Debris with ...  \n",
      "199   Machine learning-powered activatable NIR-II fl...  \n",
      "268   Plastic Mulch Effects on Hydrological Processe...  \n",
      "384   Design and Fabrication of Ergonomic Auxiliary ...  \n",
      "407   Precision Detection of the Real-Time Health an...  \n",
      "416   Nucleic Acid Sensing Analysis Based on Integra...  \n",
      "454   High-Resolution Drone Imagery and Machine Lear...  \n",
      "566   Attention-LSTM-Based Emulation of Expert Clima...  \n",
      "765   Plastic Mulch Effects on Hydrological Processe...  \n",
      "790   Techno-Economic Assessment of Atmospheric Carb...  \n",
      "810   Precision Detection of the Real-Time Health an...  \n",
      "882   Direct Biosynthesis of Organic Solvent Precurs...  \n",
      "954   Upcycling of Agri-food Resources into Packagin...  \n",
      "970   Design and Fabrication of Ergonomic Auxiliary ...  \n",
      "975   Process engineering and modelling-enabled stra...  \n",
      "976   Process engineering and modelling-enabled stra...  \n",
      "990   Techno-Economic Assessment of Atmospheric Carb...  \n",
      "1031  Advancements in Agrivoltaics: Autonomous LiDAR...  \n",
      "1035  High-Resolution Drone Imagery and Machine Lear...  \n",
      "1081  Direct Biosynthesis of Organic Solvent Precurs...  \n",
      "No duplicate rows found in df_final_presentations_25_w_embeddings (excluding 'embedding').\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate topics in the DataFrame\n",
    "duplicates = df_final_presentations_25_w_embeddings[\n",
    "    df_final_presentations_25_w_embeddings.duplicated(subset=[topic_column], keep=False)\n",
    "]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicate topics found in df_final_presentations_25_w_embeddings:\")\n",
    "    print(f\"Number of duplicate topics: {duplicates[topic_column].nunique()}\")\n",
    "    print(duplicates[[topic_column, 'topic']])\n",
    "else:\n",
    "    print(\"No duplicate topics found in df_final_presentations_25_w_embeddings.\")\n",
    "\n",
    "# Only use hashable columns for full-row duplicate check (exclude 'embedding')\n",
    "hashable_cols = [col for col in df_final_presentations_25_w_embeddings.columns if col != 'embedding']\n",
    "duplicates_all = df_final_presentations_25_w_embeddings[\n",
    "    df_final_presentations_25_w_embeddings.duplicated(subset=hashable_cols, keep=False)\n",
    "]\n",
    "if not duplicates_all.empty:\n",
    "    print(\"Duplicate rows found in df_final_presentations_25_w_embeddings (excluding 'embedding'):\")\n",
    "    print(duplicates_all)\n",
    "else:\n",
    "    print(\"No duplicate rows found in df_final_presentations_25_w_embeddings (excluding 'embedding').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6712d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all rows with duplicate topics (including the first occurrence)\n",
    "duplicates_all_versions = df_final_presentations_25_w_embeddings[\n",
    "    df_final_presentations_25_w_embeddings.duplicated(subset=[topic_column], keep=False)\n",
    "]\n",
    "\n",
    "# Drop the 'embedding' column for export\n",
    "duplicates_all_versions_no_embedding = duplicates_all_versions.drop(columns=['embedding'])\n",
    "\n",
    "# Export to CSV\n",
    "duplicates_all_versions_no_embedding.to_csv(\"duplicate_topics_all_versions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3654de50",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows without embeddings: 0\n",
      "Empty DataFrame\n",
      "Columns: [Title and Abstract]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Show rows that do NOT have embeddings added\n",
    "rows_without_embeddings = df_final_presentations_25_w_embeddings[df_final_presentations_25_w_embeddings['embedding'].isna()]\n",
    "print(f\"Number of rows without embeddings: {len(rows_without_embeddings)}\")\n",
    "print(rows_without_embeddings[[topic_column]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17f910fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_presentations_25.to_csv(\"df_final_presentations_25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60bef3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df_no_abstracts shape: (1121, 16)\n",
      "df_only_abstracts shape: (1118, 2)\n",
      "Final merged df_final_presentations_25 shape: (1121, 17)\n",
      "Number of presentations with abstracts: 1092\n",
      "Number of rows that would be dropped: 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "7 digit ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TC",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "session type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Session 1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Pres. Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Order",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Start time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "End time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Pres Auth FN",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Pres Auth LN",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Pres Affiliation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Pres Auth Location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "All Authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Student Pres?",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Unnamed: 14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unnamed: 15",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Abstract ",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "4f4da38f-90a3-4356-9836-8a1270842035",
       "rows": [
        [
         "239",
         "2501384",
         "MS-Machinery Systems",
         "Oral Session",
         "132 Robotics and Mechanization for Specialty Crops",
         "Development of A Ground-based Machine Vision System for Blueberry Maturity Assessment and Yield Estimation",
         "109",
         "4:30pm",
         "4:45pm",
         "Jiajun",
         "Xu",
         "Michigan State University",
         "East Lansing, Michigan, USA",
         "Xinyang Mu, Yuzhen Lu",
         "No",
         null,
         null,
         null
        ],
        [
         "255",
         "2500242",
         "NRES-Natural Resources & Environmental Systems",
         "Oral Session",
         "134 Advances in Micro-Irrigation and Sprinkler Irrigation Systems",
         "Evaluation of Agricultural Reservoir Supply Efficiency with Farm Pond-Pipeline Systems",
         "109",
         "4:30pm",
         "4:45pm",
         "JunYoung",
         "Lee",
         "Kangwon National University",
         "Chuncheon, Kangwon-do, Republic of Korea",
         "Sangjoon Bak, Yeonji Jeong, Seoro Lee, Jeongho Han, Gwan Jae Lee, Kyoung Jae Lim",
         "Yes",
         null,
         null,
         null
        ],
        [
         "260",
         "2500753",
         "NRES-Natural Resources & Environmental Systems",
         "Oral Session",
         "135 Hydrological Modeling, Water Resource Management, and Erosion Control Research",
         "Integrating Machine Learning and Topographic Index Models for Comprehensive Management of Ephemeral Gully Erosion",
         "106",
         "3:45pm",
         "4:00pm",
         "Hamid",
         "Mohebzadeh",
         "University of Guelph",
         "Guelph, Ontario, Canada",
         "Hamid Mohebzadeh, Asim Biswas, Ben DeVries, Ramesh Rudra, Prasad Daggupati",
         "No",
         null,
         null,
         null
        ],
        [
         "280",
         "2501662",
         "NRES-Natural Resources & Environmental Systems",
         "Oral Session",
         "138 Open-Source “pyfao56” Evapotranspiration and Water Balance Tool for Water Management",
         "WISE Pro Software for Smart Crop Irrigation and Nutrient Management Decisions",
         "109",
         "4:30pm",
         "4:45pm",
         "Mazdak",
         "Arabi",
         "Colorado State University",
         "Fort Collins, Colorado, USA",
         null,
         null,
         null,
         null,
         null
        ],
        [
         "317",
         "2500295",
         "POSTER SESSIONS",
         "Poster Session",
         "143 NRES-Advances in Environmental Systems POSTER SESSION",
         "Quantitative Analysis of Runoff in Submerged Paddy Field Areas Using SWAT-Paddy",
         "106",
         "6",
         null,
         "Yeonji",
         "Jeong",
         "Kangwon National University",
         "Chuncheon-si, Kangwon",
         "Yeonji Jeong, Gwanjae Lee, Seoro Lee, Jeongho Han, Kyoung Jae Lim",
         "Yes",
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7 digit ID</th>\n",
       "      <th>TC</th>\n",
       "      <th>session type</th>\n",
       "      <th>Session 1</th>\n",
       "      <th>Pres. Title</th>\n",
       "      <th>Order</th>\n",
       "      <th>Start time</th>\n",
       "      <th>End time</th>\n",
       "      <th>Pres Auth FN</th>\n",
       "      <th>Pres Auth LN</th>\n",
       "      <th>Pres Affiliation</th>\n",
       "      <th>Pres Auth Location</th>\n",
       "      <th>All Authors</th>\n",
       "      <th>Student Pres?</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2501384</td>\n",
       "      <td>MS-Machinery Systems</td>\n",
       "      <td>Oral Session</td>\n",
       "      <td>132 Robotics and Mechanization for Specialty C...</td>\n",
       "      <td>Development of A Ground-based Machine Vision S...</td>\n",
       "      <td>109</td>\n",
       "      <td>4:30pm</td>\n",
       "      <td>4:45pm</td>\n",
       "      <td>Jiajun</td>\n",
       "      <td>Xu</td>\n",
       "      <td>Michigan State University</td>\n",
       "      <td>East Lansing, Michigan, USA</td>\n",
       "      <td>Xinyang Mu, Yuzhen Lu</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2500242</td>\n",
       "      <td>NRES-Natural Resources &amp; Environmental Systems</td>\n",
       "      <td>Oral Session</td>\n",
       "      <td>134 Advances in Micro-Irrigation and Sprinkler...</td>\n",
       "      <td>Evaluation of Agricultural Reservoir Supply Ef...</td>\n",
       "      <td>109</td>\n",
       "      <td>4:30pm</td>\n",
       "      <td>4:45pm</td>\n",
       "      <td>JunYoung</td>\n",
       "      <td>Lee</td>\n",
       "      <td>Kangwon National University</td>\n",
       "      <td>Chuncheon, Kangwon-do, Republic of Korea</td>\n",
       "      <td>Sangjoon Bak, Yeonji Jeong, Seoro Lee, Jeongho...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2500753</td>\n",
       "      <td>NRES-Natural Resources &amp; Environmental Systems</td>\n",
       "      <td>Oral Session</td>\n",
       "      <td>135 Hydrological Modeling, Water Resource Mana...</td>\n",
       "      <td>Integrating Machine Learning and Topographic I...</td>\n",
       "      <td>106</td>\n",
       "      <td>3:45pm</td>\n",
       "      <td>4:00pm</td>\n",
       "      <td>Hamid</td>\n",
       "      <td>Mohebzadeh</td>\n",
       "      <td>University of Guelph</td>\n",
       "      <td>Guelph, Ontario, Canada</td>\n",
       "      <td>Hamid Mohebzadeh, Asim Biswas, Ben DeVries, Ra...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2501662</td>\n",
       "      <td>NRES-Natural Resources &amp; Environmental Systems</td>\n",
       "      <td>Oral Session</td>\n",
       "      <td>138 Open-Source “pyfao56” Evapotranspiration a...</td>\n",
       "      <td>WISE Pro Software for Smart Crop Irrigation an...</td>\n",
       "      <td>109</td>\n",
       "      <td>4:30pm</td>\n",
       "      <td>4:45pm</td>\n",
       "      <td>Mazdak</td>\n",
       "      <td>Arabi</td>\n",
       "      <td>Colorado State University</td>\n",
       "      <td>Fort Collins, Colorado, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2500295</td>\n",
       "      <td>POSTER SESSIONS</td>\n",
       "      <td>Poster Session</td>\n",
       "      <td>143 NRES-Advances in Environmental Systems POS...</td>\n",
       "      <td>Quantitative Analysis of Runoff in Submerged P...</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeonji</td>\n",
       "      <td>Jeong</td>\n",
       "      <td>Kangwon National University</td>\n",
       "      <td>Chuncheon-si, Kangwon</td>\n",
       "      <td>Yeonji Jeong, Gwanjae Lee, Seoro Lee, Jeongho ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     7 digit ID                                              TC  \\\n",
       "239     2501384                            MS-Machinery Systems   \n",
       "255     2500242  NRES-Natural Resources & Environmental Systems   \n",
       "260     2500753  NRES-Natural Resources & Environmental Systems   \n",
       "280     2501662  NRES-Natural Resources & Environmental Systems   \n",
       "317     2500295                                 POSTER SESSIONS   \n",
       "\n",
       "       session type                                          Session 1  \\\n",
       "239    Oral Session  132 Robotics and Mechanization for Specialty C...   \n",
       "255    Oral Session  134 Advances in Micro-Irrigation and Sprinkler...   \n",
       "260    Oral Session  135 Hydrological Modeling, Water Resource Mana...   \n",
       "280    Oral Session  138 Open-Source “pyfao56” Evapotranspiration a...   \n",
       "317  Poster Session  143 NRES-Advances in Environmental Systems POS...   \n",
       "\n",
       "                                           Pres. Title  Order Start time  \\\n",
       "239  Development of A Ground-based Machine Vision S...    109     4:30pm   \n",
       "255  Evaluation of Agricultural Reservoir Supply Ef...    109     4:30pm   \n",
       "260  Integrating Machine Learning and Topographic I...    106     3:45pm   \n",
       "280  WISE Pro Software for Smart Crop Irrigation an...    109     4:30pm   \n",
       "317  Quantitative Analysis of Runoff in Submerged P...    106          6   \n",
       "\n",
       "    End time Pres Auth FN Pres Auth LN             Pres Affiliation  \\\n",
       "239   4:45pm       Jiajun           Xu    Michigan State University   \n",
       "255   4:45pm     JunYoung          Lee  Kangwon National University   \n",
       "260   4:00pm        Hamid   Mohebzadeh         University of Guelph   \n",
       "280   4:45pm       Mazdak        Arabi    Colorado State University   \n",
       "317      NaN       Yeonji        Jeong  Kangwon National University   \n",
       "\n",
       "                           Pres Auth Location  \\\n",
       "239               East Lansing, Michigan, USA   \n",
       "255  Chuncheon, Kangwon-do, Republic of Korea   \n",
       "260                   Guelph, Ontario, Canada   \n",
       "280               Fort Collins, Colorado, USA   \n",
       "317                     Chuncheon-si, Kangwon   \n",
       "\n",
       "                                           All Authors Student Pres?  \\\n",
       "239                              Xinyang Mu, Yuzhen Lu            No   \n",
       "255  Sangjoon Bak, Yeonji Jeong, Seoro Lee, Jeongho...           Yes   \n",
       "260  Hamid Mohebzadeh, Asim Biswas, Ben DeVries, Ra...            No   \n",
       "280                                                NaN           NaN   \n",
       "317  Yeonji Jeong, Gwanjae Lee, Seoro Lee, Jeongho ...           Yes   \n",
       "\n",
       "     Unnamed: 14 Unnamed: 15 Abstract   \n",
       "239          NaN         NaN       NaN  \n",
       "255          NaN         NaN       NaN  \n",
       "260          NaN         NaN       NaN  \n",
       "280          NaN         NaN       NaN  \n",
       "317          NaN         NaN       NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the ones that were dropped\n",
    "# Merge the abstracts from df_only_abstracts into df_no_abstracts based on ID_COLUMN\n",
    "df_pre_presentations_25 = df_no_abstracts.merge(\n",
    "    df_only_abstracts, \n",
    "    on=ID_COLUMN, \n",
    "    how='left'  # Keep all rows from df_no_abstracts, add abstracts where available\n",
    ")\n",
    "\n",
    "print(f\"Original df_no_abstracts shape: {df_no_abstracts.shape}\")\n",
    "print(f\"df_only_abstracts shape: {df_only_abstracts.shape}\")\n",
    "print(f\"Final merged df_final_presentations_25 shape: {df_pre_presentations_25.shape}\")\n",
    "# Check how many presentations now have abstracts\n",
    "abstracts_added = df_final_presentations_25[ABSTRACT_COLUMN].notna().sum()\n",
    "print(f\"Number of presentations with abstracts: {abstracts_added}\")\n",
    "# Check how many presentations now have abstracts\n",
    "abstracts_added = df_pre_presentations_25[ABSTRACT_COLUMN].notna().sum()\n",
    "# Find rows that would be dropped due to missing ABSTRACT_COLUMN, TITLE_COLUMN, or ID_COLUMN\n",
    "dropped_rows = df_pre_presentations_25[\n",
    "    df_pre_presentations_25[[ABSTRACT_COLUMN, TITLE_COLUMN, ID_COLUMN]].isnull().any(axis=1)\n",
    "]\n",
    "print(f\"Number of rows that would be dropped: {len(dropped_rows)}\")\n",
    "dropped_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af37455",
   "metadata": {},
   "source": [
    "# Missing Presentations\n",
    "Some abstracts were in the drop list on 5/20 and were added back to the program. This file contains those. This code does the embedding for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6cbd080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "0: 7 digit ID\n",
      "1: Abstract\n",
      "\n",
      "File contains 29 rows and 2 columns\n",
      "\n",
      "First few rows preview:\n",
      "   7 digit ID                                           Abstract\n",
      "0     2501384  Accurate maturity assessment and yield estimat...\n",
      "1     2500242  Water resources have been regarded as a critic...\n",
      "2     2500753  Effective mitigation of ephemeral gully erosio...\n",
      "3     2501662  Diminishing water supplies and nutrient pollut...\n",
      "4     2500295  This study introduces the WAPLE4 system, devel...\n"
     ]
    }
   ],
   "source": [
    "# Add back the missing abstracts to the final DataFrame\n",
    "# Examine the Excel file structure for the abstracts.\n",
    "file_path = \"Missing Abstracts.xlsx\"\n",
    "df_temp = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Available columns:\")\n",
    "for i, col in enumerate(df_temp.columns):\n",
    "    print(f\"{i}: {col}\")\n",
    "\n",
    "print(f\"\\nFile contains {len(df_temp)} rows and {len(df_temp.columns)} columns\")\n",
    "print(\"\\nFirst few rows preview:\")\n",
    "print(df_temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd98920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your column selections based on the output above\n",
    "ABSTRACT_COLUMN = 'Abstract'  # Update based on your file  \n",
    "ID_COLUMN = '7 digit ID'  # Update based on your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fc678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_only_abstracts_missing = pd.read_excel(file_path, usecols=[ABSTRACT_COLUMN, ID_COLUMN])\n",
    "# Drop any presentations that are missing an ID number or abstract\n",
    "df_only_abstracts_missing = df_only_abstracts_missing.dropna(subset=[ABSTRACT_COLUMN, ID_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c39a6150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presentations_25_missing = df_no_abstracts.merge(\n",
    "    df_only_abstracts_missing, \n",
    "    on=ID_COLUMN, \n",
    "    how='left'  # Keep all rows from df_no_abstracts, add abstracts where available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2030ed58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df_no_abstracts shape: (1121, 16)\n",
      "df_only_abstracts shape: (1118, 2)\n",
      "Final merged df_presentations_25_missing shape: (1121, 17)\n",
      "Number of presentations with abstracts: 29\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original df_no_abstracts shape: {df_no_abstracts.shape}\")\n",
    "print(f\"df_only_abstracts shape: {df_only_abstracts.shape}\")\n",
    "print(f\"Final merged df_presentations_25_missing shape: {df_presentations_25_missing.shape}\")\n",
    "\n",
    "# Check how many presentations now have abstracts\n",
    "abstracts_added = df_presentations_25_missing[ABSTRACT_COLUMN].notna().sum()\n",
    "print(f\"Number of presentations with abstracts: {abstracts_added}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a25b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged df_presentations_25_missing shape: (29, 18)\n",
      "Number of presentations with abstracts: 29\n"
     ]
    }
   ],
   "source": [
    "topic_column='Title and Abstract'\n",
    "# Drop any presentations that are missing an ID number or abstract\n",
    "df_presentations_25_missing = df_presentations_25_missing.dropna(subset=[ABSTRACT_COLUMN, TITLE_COLUMN, ID_COLUMN])\n",
    "df_presentations_25_missing[topic_column] = df_presentations_25_missing[[TITLE_COLUMN, ABSTRACT_COLUMN]].agg(': '.join, axis=1)\n",
    "print(f\"Final merged df_presentations_25_missing shape: {df_presentations_25_missing.shape}\")\n",
    "\n",
    "# Check how many presentations now have abstracts\n",
    "abstracts_added = df_presentations_25_missing[ABSTRACT_COLUMN].notna().sum()\n",
    "print(f\"Number of presentations with abstracts: {abstracts_added}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5023b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extra columns 'Unnamed: 14', 'Unamed: 15', 'Unnamed: 16' if they exist\n",
    "extra_columns = ['Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16']\n",
    "df_presentations_25_missing = df_presentations_25_missing.drop(columns=[col for col in extra_columns if col in df_presentations_25_missing.columns], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9282e6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded from embeddings_backup.pkl\n",
      "Total topics: 29\n",
      "Already embedded: 1079\n",
      "Topics to process: 29\n",
      "Processing topic 1/29: Development of A Ground-based Machine Vision Syste...\n",
      "Successfully embedded topic 1\n",
      "Processing topic 2/29: Evaluation of Agricultural Reservoir Supply Effici...\n",
      "Successfully embedded topic 2\n",
      "Processing topic 3/29: Integrating Machine Learning and Topographic Index...\n",
      "Successfully embedded topic 3\n",
      "Processing topic 4/29: WISE Pro Software for Smart Crop Irrigation and Nu...\n",
      "Successfully embedded topic 4\n",
      "Processing topic 5/29: Quantitative Analysis of Runoff in Submerged Paddy...\n",
      "Successfully embedded topic 5\n",
      "Processing topic 6/29: Phosphoric Acid Activation of Biochar for Applicat...\n",
      "Successfully embedded topic 6\n",
      "Processing topic 7/29: Development and Evaluation of L-THIA Sub-daily mod...\n",
      "Successfully embedded topic 7\n",
      "Processing topic 8/29: Automated Cleaning Systems Effects On Long Term Ox...\n",
      "Successfully embedded topic 8\n",
      "Processing topic 9/29: Autonomous Actuation of Robotic Arm for Precise Me...\n",
      "Successfully embedded topic 9\n",
      "Processing topic 10/29: The status of precision agriculture adoption and r...\n",
      "Successfully embedded topic 10\n",
      "Processing topic 11/29: Evaluation of Changes in Watershed Runoff Characte...\n",
      "Successfully embedded topic 11\n",
      "Processing topic 12/29: A novel CNN-based approach for soil nutrient predi...\n",
      "Successfully embedded topic 12\n",
      "Processing topic 13/29: Enhancing ATV Safety: Tackling Rollover Risks with...\n",
      "Successfully embedded topic 13\n",
      "Processing topic 14/29: Sugar Beet and Multispecies Weed Detection Utilizi...\n",
      "Successfully embedded topic 14\n",
      "Processing topic 15/29: Development of a Clavel-Based Lightweight Delta Ro...\n",
      "Successfully embedded topic 15\n",
      "Processing topic 16/29: Innovative Biodesulfurization for High H₂S Biogas ...\n",
      "Successfully embedded topic 16\n",
      "Processing topic 17/29: Mitigation of gaseous emissions from swine lagoon ...\n",
      "Successfully embedded topic 17\n",
      "Processing topic 18/29: Deployment of Instance Detection Models on Edge De...\n",
      "Successfully embedded topic 18\n",
      "Processing topic 19/29: Generation of Synthetic Image Data in a Simulated ...\n",
      "Successfully embedded topic 19\n",
      "Processing topic 20/29: Virtual Farm Environments and Sim-to-Real Transfer...\n",
      "Successfully embedded topic 20\n",
      "Processing topic 21/29: Monitoring ammonia deposition around a beef cattle...\n",
      "Successfully embedded topic 21\n",
      "Processing topic 22/29: A Digital Twin of an Anaerobic Biofilter-Microalga...\n",
      "Successfully embedded topic 22\n",
      "Processing topic 23/29: Aerodynamics Properties of Silflower Seed (Silphiu...\n",
      "Successfully embedded topic 23\n",
      "Processing topic 24/29: Comparative Analysis of Plasma Jet and Surface Die...\n",
      "Successfully embedded topic 24\n",
      "Processing topic 25/29: Automated Weed Pressure Measurement System Evaluat...\n",
      "Successfully embedded topic 25\n",
      "Processing topic 26/29: Preliminary Analysis of Computer Vision for Blackb...\n",
      "Successfully embedded topic 26\n",
      "Processing topic 27/29: INTEGRATED APPROACH FOR NUTRIENT LOSS REDUCTION AN...\n",
      "Successfully embedded topic 27\n",
      "Processing topic 28/29: Watershed Management Approach Integrating the SWAT...\n",
      "Successfully embedded topic 28\n",
      "Processing topic 29/29: Integrating Machine Learning and Remote Sensing fo...\n",
      "Successfully embedded topic 29\n",
      "Embeddings saved to embeddings_backup.pkl\n"
     ]
    }
   ],
   "source": [
    "df_embeddings_missing = embed_with_resume(df_presentations_25_missing, topic_column, 'gemini-embedding-exp-03-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b60e0b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings column added to df_presentations_25_missing.\n"
     ]
    }
   ],
   "source": [
    "# Merge embeddings into df_final_presentations_25 based on the topic_column\n",
    "df_presentations_25_missing_w_embeddings = df_presentations_25_missing.merge(\n",
    "    df_embeddings_missing[['topic', 'embedding']].drop_duplicates(subset=['topic']),\n",
    "    left_on=topic_column,\n",
    "    right_on='topic',\n",
    "    how='left'\n",
    ")\n",
    "print(\"Embeddings column added to df_presentations_25_missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde4472",
   "metadata": {},
   "source": [
    "# Add guest and other speakers without ID numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc85a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "0: 7 digit ID\n",
      "1: TC\n",
      "2: session type\n",
      "3: Session 1\n",
      "4: Pres. Title\n",
      "5: Order\n",
      "6: Start time\n",
      "7: End time\n",
      "8: Pres Auth FN\n",
      "9: Pres Auth LN\n",
      "10: Pres Affiliation\n",
      "11: Pres Auth Location\n",
      "12: All Authors\n",
      "13: Student Pres?\n",
      "\n",
      "File contains 44 rows and 14 columns\n",
      "\n",
      "First few rows preview:\n",
      "      7 digit ID                                                 TC  \\\n",
      "0  Guest Speaker         CBSI-Circular Bioeconomy Systems Institute   \n",
      "1  Guest Speaker         CBSI-Circular Bioeconomy Systems Institute   \n",
      "2            NaN  EOPD-Education, Outreach, & Professional Devel...   \n",
      "3  Guest Speaker     NRES-Natural Resources & Environmental Systems   \n",
      "4  Guest Speaker     NRES-Natural Resources & Environmental Systems   \n",
      "\n",
      "            session type                                          Session 1  \\\n",
      "0         Hybrid Session  102 Advancing Circular Bioeconomy Systems (CBS...   \n",
      "1         Hybrid Session  102 Advancing Circular Bioeconomy Systems (CBS...   \n",
      "2            Rap Session  104 Engineering Ethics across Cultures-RAP SES...   \n",
      "3  Guest Speaker Session  117 NRES Distinguished Lecture Series - AI and...   \n",
      "4  Guest Speaker Session  117 NRES Distinguished Lecture Series - AI and...   \n",
      "\n",
      "                                         Pres. Title  Order Start time  \\\n",
      "0  Advancing Circular Bioeconomy Systems (CBS): O...  101.0     9:35am   \n",
      "1  Advancing Circular Bioeconomy Systems (CBS): O...  106.0    10:50am   \n",
      "2     Engineering Ethics across Cultures-RAP Session    NaN        NaN   \n",
      "3  NRES Distinguished Lecture Series - AI and Dig...  101.0     9:30am   \n",
      "4  Ramping up AI in the Classroom, for Student Su...  102.0     9:35am   \n",
      "\n",
      "  End time Pres Auth FN Pres Auth LN                Pres Affiliation  \\\n",
      "0  10:00am       Bishnu      Acharya      University of Saskatchewan   \n",
      "1  11:15am       Shahab   Sokhansanj  University of British Columbia   \n",
      "2      NaN          NaN          NaN                             NaN   \n",
      "3   9:35am        Derek       Heeren  University of Nebraska-Lincoln   \n",
      "4   9:45am       Carmen    Agouridis          University of Kentucky   \n",
      "\n",
      "                    Pres Auth Location All Authors Student Pres?  \n",
      "0      Saskatoon, Saskatchewan, Canada         NaN           NaN  \n",
      "1  Vancouver, British Columbia, Canada         NaN           NaN  \n",
      "2                                  NaN         NaN           NaN  \n",
      "3               Lincoln, Nebraska, USA         NaN           NaN  \n",
      "4             Lexington, Kentucky, USA         NaN           NaN  \n"
     ]
    }
   ],
   "source": [
    "# Examine the Excel file structure .\n",
    "file_path = \"AIM 25 Final Speakers No ID Num.xlsx\"\n",
    "df_temp = pd.read_excel(file_path)\n",
    "\n",
    "print(\"Available columns:\")\n",
    "for i, col in enumerate(df_temp.columns):\n",
    "    print(f\"{i}: {col}\")\n",
    "\n",
    "print(f\"\\nFile contains {len(df_temp)} rows and {len(df_temp.columns)} columns\")\n",
    "print(\"\\nFirst few rows preview:\")\n",
    "print(df_temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9bc1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_ID = pd.read_excel(file_path)\n",
    "\n",
    "TITLE_COLUMN = 'Pres. Title'  # Update based on your file\n",
    "# Drop any presentations that are missing an ID number or title\n",
    "df_no_ID = df_no_ID.dropna(subset=[TITLE_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1d248c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged df_no_ID shape: (44, 15)\n"
     ]
    }
   ],
   "source": [
    "topic_column='Title and Abstract'\n",
    "\n",
    "df_no_ID[topic_column] = df_no_ID[TITLE_COLUMN]\n",
    "print(f\"Final merged df_no_ID shape: {df_no_ID.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7257e9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded from embeddings_backup.pkl\n",
      "Total topics: 44\n",
      "Already embedded: 1108\n",
      "Topics to process: 44\n",
      "Processing topic 1/44: Advancing Circular Bioeconomy Systems (CBS): Oppor...\n",
      "Successfully embedded topic 1\n",
      "Processing topic 2/44: Advancing Circular Bioeconomy Systems (CBS): Oppor...\n",
      "Successfully embedded topic 2\n",
      "Processing topic 3/44: Engineering Ethics across Cultures-RAP Session...\n",
      "Successfully embedded topic 3\n",
      "Processing topic 4/44: NRES Distinguished Lecture Series - AI and Digital...\n",
      "Successfully embedded topic 4\n",
      "Processing topic 5/44: Ramping up AI in the Classroom, for Student Succes...\n",
      "Successfully embedded topic 5\n",
      "Processing topic 6/44: Industry and Academic Perspectives on AI tools...\n",
      "Successfully embedded topic 6\n",
      "Processing topic 7/44: AI Tools for International Online Education and Wo...\n",
      "Successfully embedded topic 7\n",
      "Processing topic 8/44: Development of AI Tools for Water Management...\n",
      "Successfully embedded topic 8\n",
      "Processing topic 9/44: Assessing Benefits and Concerns of AI Tools for St...\n",
      "Successfully embedded topic 9\n",
      "Processing topic 10/44: NRES Distinguished Lecture Series - AI and Digital...\n",
      "Successfully embedded topic 10\n",
      "Processing topic 11/44: NRES Distinguished Lecture Series - AI and Digital...\n",
      "Successfully embedded topic 11\n",
      "Processing topic 12/44: NRES Distinguished Lecture Series - AI and Digital...\n",
      "Successfully embedded topic 12\n",
      "Processing topic 13/44: Educating grain industry professionals...\n",
      "Successfully embedded topic 13\n",
      "Processing topic 14/44: Training the next generation of leaders for a tran...\n",
      "Successfully embedded topic 14\n",
      "Processing topic 15/44: Grain postharvest education in South East Asia...\n",
      "Successfully embedded topic 15\n",
      "Processing topic 16/44: Training graduate students in particle technology ...\n",
      "Successfully embedded topic 16\n",
      "Processing topic 17/44: Grain postharvest education in Canada...\n",
      "Successfully embedded topic 17\n",
      "Processing topic 18/44: Grain postharvest education in India...\n",
      "Successfully embedded topic 18\n",
      "Processing topic 19/44: Natural Resources and Environmental Systems Commun...\n",
      "Successfully embedded topic 19\n",
      "Processing topic 20/44: International collaboration and work opportunities...\n",
      "Successfully embedded topic 20\n",
      "Processing topic 21/44: Introducition to International Collaboration at th...\n",
      "Successfully embedded topic 21\n",
      "Processing topic 22/44: In Memory of Prof. Maohua Wang...\n",
      "Successfully embedded topic 22\n",
      "Processing topic 23/44: Panel Discussion: Navigating Challenges and Paths ...\n",
      "Successfully embedded topic 23\n",
      "Processing topic 24/44: Exploring Safety in the Era of Autonomous Agricult...\n",
      "Successfully embedded topic 24\n",
      "Processing topic 25/44: Information Technology, Sensors & Control Systems ...\n",
      "Successfully embedded topic 25\n",
      "Processing topic 26/44: Machine Learning and Proximal Sensing to Advance F...\n",
      "Successfully embedded topic 26\n",
      "Processing topic 27/44: Ontario Livestock Manure Management Perspective – ...\n",
      "Successfully embedded topic 27\n",
      "Processing topic 28/44: Comprehensive research and data to consider manure...\n",
      "Successfully embedded topic 28\n",
      "Processing topic 29/44: Efforts of Ontario livestock industry in environme...\n",
      "Successfully embedded topic 29\n",
      "Processing topic 30/44: Ontario’s AgriSuite Nutrient Management Decision S...\n",
      "Successfully embedded topic 30\n",
      "Processing topic 31/44: Application and potential of Manure Tech Decision ...\n",
      "Successfully embedded topic 31\n",
      "Processing topic 32/44: Ontario Perspective on Sustainable Manure Manageme...\n",
      "Successfully embedded topic 32\n",
      "Processing topic 33/44: Current Status of Robot and Data-Driven Digital Ag...\n",
      "Successfully embedded topic 33\n",
      "Processing topic 34/44: Adaptation and value creation of land and water fo...\n",
      "Successfully embedded topic 34\n",
      "Processing topic 35/44:  Technology Trends and Career Opportunities in the...\n",
      "Successfully embedded topic 35\n",
      "Processing topic 36/44: Identifying Common Attributes of an Agricultural a...\n",
      "Successfully embedded topic 36\n",
      "Processing topic 37/44: How does \"one water\" planning fit with  the spheri...\n",
      "Successfully embedded topic 37\n",
      "Processing topic 38/44: Ecological Engineering Solutions Validated through...\n",
      "Successfully embedded topic 38\n",
      "Processing topic 39/44: Empowering Students Through Experiential Learning ...\n",
      "Successfully embedded topic 39\n",
      "Processing topic 40/44: TIM and Autonomy in Ag - What is the AEF up to?...\n",
      "Successfully embedded topic 40\n",
      "Processing topic 41/44: The Impact of Digital Revolution on Controlled Env...\n",
      "Successfully embedded topic 41\n",
      "Processing topic 42/44: The Enduring Value of ASABE Professional Relations...\n",
      "Successfully embedded topic 42\n",
      "Processing topic 43/44: Best Practices for Advancing PAFS Community Contri...\n",
      "Successfully embedded topic 43\n",
      "Processing topic 44/44: Learning and Leading with Purpose: My ASABE Journe...\n",
      "Successfully embedded topic 44\n",
      "Embeddings saved to embeddings_backup.pkl\n"
     ]
    }
   ],
   "source": [
    "df_embeddings_no_ID = embed_with_resume(df_no_ID, topic_column, 'gemini-embedding-exp-03-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1aa3e168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings column added to df_no_ID.\n"
     ]
    }
   ],
   "source": [
    "# Merge embeddings into df_final_presentations_25 based on the topic_column\n",
    "df_no_ID_w_embeddings = df_no_ID.merge(\n",
    "    df_embeddings_no_ID[['topic', 'embedding']].drop_duplicates(subset=['topic']),\n",
    "    left_on=topic_column,\n",
    "    right_on='topic',\n",
    "    how='left'\n",
    ")\n",
    "print(\"Embeddings column added to df_no_ID.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795acd2b",
   "metadata": {},
   "source": [
    "# Combine the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7cfe0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Abstract ' (with trailing space) to 'Abstract' in df_final_presentations_25_w_embeddings\n",
    "df_final_presentations_25_w_embeddings = df_final_presentations_25_w_embeddings.rename(columns={'Abstract ': 'Abstract'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "79a91c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df_final_presentations_25_w_embeddings but not in df_no_ID_w_embeddings:\n",
      "{'Abstract'}\n",
      "\n",
      "Columns in df_no_ID_w_embeddings but not in df_final_presentations_25_w_embeddings:\n",
      "set()\n",
      "\n",
      "Columns in df_presentations_25_missing_w_embeddings but not in df_final_presentations_25_w_embeddings:\n",
      "set()\n",
      "\n",
      "Columns in df_final_presentations_25_w_embeddings but not in df_presentations_25_missing_w_embeddings:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check for matching columns (except for 'Abstract')\n",
    "\n",
    "# Get sets of columns for each DataFrame\n",
    "cols_main = set(df_final_presentations_25_w_embeddings.columns)\n",
    "cols_missing = set(df_presentations_25_missing_w_embeddings.columns)\n",
    "cols_no_id = set(df_no_ID_w_embeddings.columns)\n",
    "\n",
    "# Find differences\n",
    "print(\"Columns in df_final_presentations_25_w_embeddings but not in df_no_ID_w_embeddings:\")\n",
    "print(cols_main - cols_no_id)\n",
    "\n",
    "print(\"\\nColumns in df_no_ID_w_embeddings but not in df_final_presentations_25_w_embeddings:\")\n",
    "print(cols_no_id - cols_main)\n",
    "\n",
    "print(\"\\nColumns in df_presentations_25_missing_w_embeddings but not in df_final_presentations_25_w_embeddings:\")\n",
    "print(cols_missing - cols_main)\n",
    "\n",
    "print(\"\\nColumns in df_final_presentations_25_w_embeddings but not in df_presentations_25_missing_w_embeddings:\")\n",
    "print(cols_main - cols_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e66a0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_w_embeddings = pd.concat([\n",
    "    df_final_presentations_25_w_embeddings,\n",
    "    df_presentations_25_missing_w_embeddings,\n",
    "    df_no_ID_w_embeddings\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1ac6e",
   "metadata": {},
   "source": [
    "# Duplicate Presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c86d011",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate topics found in df_all_w_embeddings:\n",
      "Number of duplicate topics: 14\n",
      "                                     Title and Abstract  \\\n",
      "0     Upcycling of Agri-food Resources into Packagin...   \n",
      "21    Advancements in Agrivoltaics: Autonomous LiDAR...   \n",
      "25    Watt a Waste: Utilizing Hurricane Debris with ...   \n",
      "82    Machine learning-powered activatable NIR-II fl...   \n",
      "94    Nucleic Acid Sensing Analysis Based on Integra...   \n",
      "101   Attention-LSTM-Based Emulation of Expert Clima...   \n",
      "187   Watt a Waste: Utilizing Hurricane Debris with ...   \n",
      "199   Machine learning-powered activatable NIR-II fl...   \n",
      "268   Plastic Mulch Effects on Hydrological Processe...   \n",
      "384   Design and Fabrication of Ergonomic Auxiliary ...   \n",
      "407   Precision Detection of the Real-Time Health an...   \n",
      "416   Nucleic Acid Sensing Analysis Based on Integra...   \n",
      "454   High-Resolution Drone Imagery and Machine Lear...   \n",
      "566   Attention-LSTM-Based Emulation of Expert Clima...   \n",
      "765   Plastic Mulch Effects on Hydrological Processe...   \n",
      "790   Techno-Economic Assessment of Atmospheric Carb...   \n",
      "810   Precision Detection of the Real-Time Health an...   \n",
      "882   Direct Biosynthesis of Organic Solvent Precurs...   \n",
      "954   Upcycling of Agri-food Resources into Packagin...   \n",
      "970   Design and Fabrication of Ergonomic Auxiliary ...   \n",
      "975   Process engineering and modelling-enabled stra...   \n",
      "976   Process engineering and modelling-enabled stra...   \n",
      "990   Techno-Economic Assessment of Atmospheric Carb...   \n",
      "1031  Advancements in Agrivoltaics: Autonomous LiDAR...   \n",
      "1035  High-Resolution Drone Imagery and Machine Lear...   \n",
      "1081  Direct Biosynthesis of Organic Solvent Precurs...   \n",
      "1121  Advancing Circular Bioeconomy Systems (CBS): O...   \n",
      "1122  Advancing Circular Bioeconomy Systems (CBS): O...   \n",
      "\n",
      "                                                  topic  \n",
      "0     Upcycling of Agri-food Resources into Packagin...  \n",
      "21    Advancements in Agrivoltaics: Autonomous LiDAR...  \n",
      "25    Watt a Waste: Utilizing Hurricane Debris with ...  \n",
      "82    Machine learning-powered activatable NIR-II fl...  \n",
      "94    Nucleic Acid Sensing Analysis Based on Integra...  \n",
      "101   Attention-LSTM-Based Emulation of Expert Clima...  \n",
      "187   Watt a Waste: Utilizing Hurricane Debris with ...  \n",
      "199   Machine learning-powered activatable NIR-II fl...  \n",
      "268   Plastic Mulch Effects on Hydrological Processe...  \n",
      "384   Design and Fabrication of Ergonomic Auxiliary ...  \n",
      "407   Precision Detection of the Real-Time Health an...  \n",
      "416   Nucleic Acid Sensing Analysis Based on Integra...  \n",
      "454   High-Resolution Drone Imagery and Machine Lear...  \n",
      "566   Attention-LSTM-Based Emulation of Expert Clima...  \n",
      "765   Plastic Mulch Effects on Hydrological Processe...  \n",
      "790   Techno-Economic Assessment of Atmospheric Carb...  \n",
      "810   Precision Detection of the Real-Time Health an...  \n",
      "882   Direct Biosynthesis of Organic Solvent Precurs...  \n",
      "954   Upcycling of Agri-food Resources into Packagin...  \n",
      "970   Design and Fabrication of Ergonomic Auxiliary ...  \n",
      "975   Process engineering and modelling-enabled stra...  \n",
      "976   Process engineering and modelling-enabled stra...  \n",
      "990   Techno-Economic Assessment of Atmospheric Carb...  \n",
      "1031  Advancements in Agrivoltaics: Autonomous LiDAR...  \n",
      "1035  High-Resolution Drone Imagery and Machine Lear...  \n",
      "1081  Direct Biosynthesis of Organic Solvent Precurs...  \n",
      "1121  Advancing Circular Bioeconomy Systems (CBS): O...  \n",
      "1122  Advancing Circular Bioeconomy Systems (CBS): O...  \n",
      "No duplicate rows found in df_all_w_embeddings (excluding 'embedding').\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate topics in the DataFrame\n",
    "duplicates = df_all_w_embeddings[\n",
    "    df_all_w_embeddings.duplicated(subset=[topic_column], keep=False)\n",
    "]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicate topics found in df_all_w_embeddings:\")\n",
    "    print(f\"Number of duplicate topics: {duplicates[topic_column].nunique()}\")\n",
    "    print(duplicates[[topic_column, 'topic']])\n",
    "else:\n",
    "    print(\"No duplicate topics found in df_all_w_embeddings.\")\n",
    "\n",
    "# Only use hashable columns for full-row duplicate check (exclude 'embedding')\n",
    "hashable_cols = [col for col in df_all_w_embeddings.columns if col != 'embedding']\n",
    "duplicates_all = df_all_w_embeddings[\n",
    "    df_all_w_embeddings.duplicated(subset=hashable_cols, keep=False)\n",
    "]\n",
    "if not duplicates_all.empty:\n",
    "    print(\"Duplicate rows found in df_all_w_embeddings (excluding 'embedding'):\")\n",
    "    print(duplicates_all)\n",
    "else:\n",
    "    print(\"No duplicate rows found in df_all_w_embeddings (excluding 'embedding').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "610b242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all rows with duplicate topics (including the first occurrence)\n",
    "duplicates_full = df_all_w_embeddings[\n",
    "    df_all_w_embeddings.duplicated(subset=[topic_column], keep=False)\n",
    "]\n",
    "\n",
    "# Drop the 'embedding' column for export\n",
    "duplicates_full_no_embedding = duplicates_full.drop(columns=['embedding'])\n",
    "\n",
    "# Export to CSV\n",
    "duplicates_full_no_embedding.to_csv(\"duplicate_topics_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ae5ccdfc",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows without embeddings: 0\n",
      "Empty DataFrame\n",
      "Columns: [Title and Abstract]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Show rows that do NOT have embeddings added\n",
    "rows_without_embeddings = df_all_w_embeddings[df_all_w_embeddings['embedding'].isna()]\n",
    "print(f\"Number of rows without embeddings: {len(rows_without_embeddings)}\")\n",
    "print(rows_without_embeddings[[topic_column]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d144e",
   "metadata": {},
   "source": [
    "# Export Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c07b3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split  the 'embedding' column for export\n",
    "df_all_no_embeddings = df_all_w_embeddings.drop(columns=['embedding'])\n",
    "df_all_embeddings = df_all_w_embeddings['embedding']\n",
    "\n",
    "# Export to CSV\n",
    "df_all_no_embeddings.to_csv(\"Full Presentation List.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7a03e",
   "metadata": {},
   "source": [
    "## Create similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "986037cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Convert the embeddings Series to a 2D numpy array\n",
    "embeddings_matrix = np.vstack(df_all_embeddings.dropna().values)\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(embeddings_matrix)\n",
    "\n",
    "# print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556ad61",
   "metadata": {},
   "source": [
    "## Create sharable dataframe\n",
    "Abstracts, names and emails should not be posted openly on the web. Remove them from the non-encrypted basic version of the data set.\n",
    "\n",
    "First, check what columns are available. Then select the ones to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8808510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "0: 7 digit ID\n",
      "1: TC\n",
      "2: session type\n",
      "3: Session 1\n",
      "4: Pres. Title\n",
      "5: Order\n",
      "6: Start time\n",
      "7: End time\n",
      "8: Pres Auth FN\n",
      "9: Pres Auth LN\n",
      "10: Pres Affiliation\n",
      "11: Pres Auth Location\n",
      "12: All Authors\n",
      "13: Student Pres?\n",
      "14: Abstract\n",
      "15: Title and Abstract\n",
      "16: topic\n",
      "Dataframe contains 1165 rows and 17 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Available columns:\")\n",
    "for i, col in enumerate(df_all_no_embeddings.columns):\n",
    "    print(f\"{i}: {col}\")\n",
    "\n",
    "print(f\"Dataframe contains {len(df_all_no_embeddings)} rows and {len(df_all_no_embeddings.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7b1801b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed columns:\n",
      "['7 digit ID', 'Technical Community', 'Session Type', 'Session', 'Presentation Title', 'Order', 'Start time', 'End time', 'Presenter First Name', 'Presenter Last Name', 'Presenter Affiliation', 'Presenter Location', 'All Authors', 'Student Pres?', 'Abstract', 'Title and Abstract', 'topic']\n"
     ]
    }
   ],
   "source": [
    "rename_dict = {\n",
    "    # \"Current Name\": \"New Name\",\n",
    "    # For example:\n",
    "    \"digit ID\": \"7 Digit ID\",\n",
    "    \"TC\": \"Technical Community\",\n",
    "    \"session type\": \"Session Type\",\n",
    "    \"Session 1\": \"Session\",\n",
    "    \"Pres. Title\": \"Presentation Title\",\n",
    "    \"Order\": \"Order\",\n",
    "    \"Start time:\": \"Start Time or Poster Position\",\n",
    "    \"End time:\": \"End Time\",\n",
    "    \"Pres Auth FN\": \"Presenter First Name\",\n",
    "    \"Pres Auth LN\": \"Presenter Last Name\",\n",
    "    \"Pres Affiliation\": \"Presenter Affiliation\",\n",
    "    \"Pres Auth Location\": \"Presenter Location\",\n",
    "    # Add more renaming rules as needed\n",
    "}\n",
    "# Apply renaming\n",
    "df_all_no_embeddings = df_all_no_embeddings.rename(columns=rename_dict)\n",
    "\n",
    "print(\"Renamed columns:\")\n",
    "print(df_all_no_embeddings.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4091c",
   "metadata": {},
   "source": [
    "# Create Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e6a36a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_sessions created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jdv223\\AppData\\Local\\Temp\\ipykernel_44664\\1050398111.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sessions = df_all_no_embeddings.groupby(session_column_name).apply(lambda x: pd.Series({\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Session Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Session Size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gen_presentation_indices",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "0f277b78-23de-4612-a5f2-f911887f3995",
       "rows": [
        [
         "0",
         "101 Biomass Preprocessing and Logistics for Biofuels and Bioproducts",
         "7",
         "[0, 1, 2, 3, 4, 5, 6]"
        ],
        [
         "1",
         "102 Advancing Circular Bioeconomy Systems (CBS): Opportunities and Challenges-HYBRID",
         "8",
         "[7, 8, 9, 10, 11, 12, 1121, 1122]"
        ],
        [
         "2",
         "103 China Exchange & AOCABFE Business Meeting-PANEL",
         "4",
         "[1140, 1141, 1142, 1143]"
        ],
        [
         "3",
         "104 Engineering Ethics across Cultures-RAP SESSION",
         "1",
         "[1123]"
        ],
        [
         "4",
         "105 Advances in Biomass Preprocessing, Pretreatment, and Conversion",
         "8",
         "[13, 14, 15, 16, 17, 18, 19, 20]"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session Name</th>\n",
       "      <th>Session Size</th>\n",
       "      <th>gen_presentation_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101 Biomass Preprocessing and Logistics for Bi...</td>\n",
       "      <td>7</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102 Advancing Circular Bioeconomy Systems (CBS...</td>\n",
       "      <td>8</td>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 1121, 1122]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103 China Exchange &amp; AOCABFE Business Meeting-...</td>\n",
       "      <td>4</td>\n",
       "      <td>[1140, 1141, 1142, 1143]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104 Engineering Ethics across Cultures-RAP SES...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1123]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105 Advances in Biomass Preprocessing, Pretrea...</td>\n",
       "      <td>8</td>\n",
       "      <td>[13, 14, 15, 16, 17, 18, 19, 20]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Session Name  Session Size  \\\n",
       "0  101 Biomass Preprocessing and Logistics for Bi...             7   \n",
       "1  102 Advancing Circular Bioeconomy Systems (CBS...             8   \n",
       "2  103 China Exchange & AOCABFE Business Meeting-...             4   \n",
       "3  104 Engineering Ethics across Cultures-RAP SES...             1   \n",
       "4  105 Advances in Biomass Preprocessing, Pretrea...             8   \n",
       "\n",
       "            gen_presentation_indices  \n",
       "0              [0, 1, 2, 3, 4, 5, 6]  \n",
       "1  [7, 8, 9, 10, 11, 12, 1121, 1122]  \n",
       "2           [1140, 1141, 1142, 1143]  \n",
       "3                             [1123]  \n",
       "4   [13, 14, 15, 16, 17, 18, 19, 20]  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_column_name = 'Session'\n",
    "\n",
    "# Group by the session column and aggregate the results\n",
    "df_sessions = df_all_no_embeddings.groupby(session_column_name).apply(lambda x: pd.Series({\n",
    "    'Session Name': x.name,\n",
    "    'Session Size': len(x),\n",
    "    'gen_presentation_indices': x.index.tolist()\n",
    "})).reset_index(drop=True)\n",
    "\n",
    "print(\"df_sessions created successfully.\")\n",
    "df_sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70507086",
   "metadata": {},
   "source": [
    "### Analyze Sessions\n",
    "- session_coherence = \"Are presentations within this session similar?\" (internal session quality)\n",
    "- session_distinctiveness = \"Is this session's topic unique compared to others?\" (relative session positioning)\n",
    "- presentation_session_fit = \"Does this presentation match the topic of others in the session?\" (presentation fit)\n",
    "\n",
    "Session Coherence measures cluster cohesion. It reflects how tighly grouped the topic of presentations within the session are.\n",
    "\n",
    "Session Distinctiveness measures how unique each session's topic is. High values mean the session has a clear, focused theme that's different from other sessions. Low values suggest either the session mixes different topics or overlaps too much with other sessions.\n",
    "\n",
    "Presentation-Session Fit is an individual presentations's average similarity to other presentation in its session. Generically, it can be referred to as \"within_cluster_fit\", \"cluster_membership_strength\", or \"local_cohesion_score\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2c2f25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from sklearn.metrics import silhouette_samples\n",
    "def calculate_placement_metrics(df_presentations, df_sessions, pres_similarities_matrix, session_column_name='Session Code'):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive quality metrics for session assignments.\n",
    "    \n",
    "    This function computes three key metrics to evaluate how well presentations \n",
    "    are organized into sessions:\n",
    "    \n",
    "    1. Session Coherence: Average pairwise similarity within each session \n",
    "        (measures internal session quality)\n",
    "    2. Session Distinctiveness: Silhouette score for each session \n",
    "        (measures how unique/separable each session is from others)\n",
    "    3. Presentation-Session Fit: For each presentation, average similarity \n",
    "        to other presentations in the same session (measures individual fit)\n",
    "\n",
    "    Args:\n",
    "        df_presentations (pd.DataFrame): DataFrame containing presentation data with \n",
    "            session assignments in the specified column.\n",
    "        df_sessions (pd.DataFrame): DataFrame containing session metadata with \n",
    "            presentation indices stored in session_organizer.COLUMNS['GEN_PRESENTATION_INDICES'].\n",
    "        pres_similarities_matrix (np.ndarray): Symmetric similarity matrix where \n",
    "            element [i,j] represents similarity between presentations i and j.\n",
    "        session_column_name (str, optional): Column name in df_presentations that \n",
    "            contains session identifiers. Defaults to 'Session Code'.\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, pd.DataFrame]: A tuple containing:\n",
    "            - df_sessions: Updated with 'session_coherence' and 'session_distinctiveness' columns\n",
    "            - df_presentations: Updated with 'presentation_session_fit' column\n",
    "            \n",
    "    Raises:\n",
    "        AssertionError: If presentation indices exceed the valid range for df_presentations.\n",
    "        \n",
    "    Note:\n",
    "        The function modifies the input DataFrames in place and also returns them.\n",
    "        Silhouette scores range from -1 to 1, where higher values indicate better separation.\n",
    "        Similarity scores depend on the embedding model used but typically range from 0 to 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert similarity to distance for silhouette calculation\n",
    "    distance_matrix = 1 - pres_similarities_matrix\n",
    "    # Perfect matches which occurs on the diagonal should have similiarity of 1 or \n",
    "    # distance 0, but they often don't due to numerical instability. \n",
    "    # So we ensure the diagonal is 0 to avoid self-similarity issues.\n",
    "    np.fill_diagonal(distance_matrix, 0)\n",
    "    # Any duplicates not removed should also have a distance of 0.\n",
    "    # These will not appear on the diagonal, but we ensure no negative distances.\n",
    "    distance_matrix[distance_matrix < 0] = 0\n",
    "\n",
    "    pres_indices_by_session = df_sessions['gen_presentation_indices']\n",
    "    pos_to_ind, ind_to_pos= session_organizer.create_index_mappings(df_presentations)   \n",
    "    pres_positions_by_session = pres_indices_by_session.apply(lambda indices_list: [ind_to_pos[i] for i in indices_list])\n",
    "    # Set the index of pres_positions_by_session to be the session names for easier lookup\n",
    "    pres_positions_by_session.index = df_sessions['Session Name']\n",
    "    max_position = max(chain.from_iterable(pres_positions_by_session))\n",
    "    # Ensure max_position is within valid range\n",
    "    assert max_position <= len(df_presentations) - 1, (\n",
    "        f\"Maximum position {max_position} exceeds maximum valid index {len(df_presentations) - 1} for df_presentations of length {len(df_presentations)}\"\n",
    "    )\n",
    "\n",
    "    # Initialize outputs\n",
    "    session_session_similarity_dataframe = pd.DataFrame(index=df_sessions['Session Name'], columns=df_sessions['Session Name'])\n",
    "    session_average_similarity_series = pd.Series(index=df_sessions['Session Name'], dtype=float, name='session_coherence')\n",
    "    presentation_session_fit_series = pd.Series(index=df_presentations.index, dtype=float, name='presentation_session_fit')\n",
    "\n",
    "\n",
    "    # Calculate the silhouette scores for each presentation first\n",
    "    # Get the assigned labels for each presentation\n",
    "    labels_str = df_presentations[session_column_name].values\n",
    "    # Convert string labels to numeric labels for silhouette_samples\n",
    "    unique_labels, labels_numeric = pd.factorize(labels_str)\n",
    "    sample_scores = silhouette_samples(distance_matrix, unique_labels, metric='precomputed')\n",
    "\n",
    "    # Create a pandas Series for session distinctiveness with matching index\n",
    "    session_distinctiveness_series = pd.Series(index=df_sessions.index, dtype=float, name='session_distinctiveness')\n",
    "\n",
    "    # Calculate average silhouette score for each cluster\n",
    "    for i, cluster_name in enumerate(labels_numeric):\n",
    "        cluster_mask = labels_str == cluster_name\n",
    "        if np.sum(cluster_mask) > 0:\n",
    "            cluster_score = np.mean(sample_scores[cluster_mask])\n",
    "            # Find the corresponding index in df_sessions\n",
    "            session_index = df_sessions[df_sessions['Session Name'] == cluster_name].index\n",
    "            if not session_index.empty:\n",
    "                session_distinctiveness_series.loc[session_index[0]] = cluster_score\n",
    "\n",
    "\n",
    "    # Calculate average similarity for each session\n",
    "    for session_id_i, positions_i in pres_positions_by_session.items():\n",
    "        for session_id_j, positions_j in pres_positions_by_session.items():\n",
    "            if not positions_i or not positions_j:\n",
    "                session_session_similarity_dataframe.loc[session_id_i, session_id_j] = 0.0\n",
    "                continue\n",
    "            session_i_to_j_similarities = pres_similarities_matrix[np.ix_(positions_i, positions_j)]\n",
    "            if session_id_i == session_id_j:\n",
    "                # First calculate the presentation to session similarities\n",
    "                # Mask the diagonal (self-similarity) by setting it to np.nan, then compute mean of each row ignoring nan\n",
    "                session_i_to_j_similarities_no_diag = session_i_to_j_similarities.copy()\n",
    "                np.fill_diagonal(session_i_to_j_similarities_no_diag, np.nan)\n",
    "                presentation_session_fits = np.nanmean(session_i_to_j_similarities_no_diag, axis=1)\n",
    "                for i, pos in enumerate(positions_i):\n",
    "                    presentation_session_fit_series.loc[pos_to_ind[pos]] = presentation_session_fits[i]\n",
    "                # Same session: use upper triangle to avoid double-counting pairs\n",
    "                n = session_i_to_j_similarities.shape[0]\n",
    "                if n > 1:\n",
    "                    triu_indices = np.triu_indices(n, k=1)\n",
    "                    avg_similarity = np.mean(session_i_to_j_similarities[triu_indices])\n",
    "                    # Store the average similarity in the series for this session\n",
    "                    session_average_similarity_series.loc[session_id_i] = avg_similarity\n",
    "                else:\n",
    "                    avg_similarity = 0.0\n",
    "            else:\n",
    "                # Different sessions: use all similarities\n",
    "                avg_similarity = np.mean(session_i_to_j_similarities)\n",
    "            session_session_similarity_dataframe.loc[session_id_i, session_id_j] = avg_similarity\n",
    "\n",
    "    # Calculate standard deviation of presentation fits for each session\n",
    "    session_std_series = presentation_session_fit_series.groupby(df_presentations[session_column_name]).std()\n",
    "    session_std_series.name = 'session_std'\n",
    "\n",
    "    # Map session average similarity and std dev to each presentation\n",
    "    presentation_session_avg_map = df_presentations[session_column_name].map(session_average_similarity_series)\n",
    "    presentation_session_std_map = df_presentations[session_column_name].map(session_std_series)\n",
    "\n",
    "    # Calculate raw and standardized deviation for each presentation\n",
    "    presentation_raw_deviation_series = presentation_session_fit_series - presentation_session_avg_map\n",
    "    presentation_raw_deviation_series.name = 'presentation_raw_deviation'\n",
    "    \n",
    "    presentation_std_series = presentation_raw_deviation_series / presentation_session_std_map\n",
    "    presentation_std_series.name = 'presentation_std'\n",
    "            \n",
    "    return (presentation_session_fit_series, session_average_similarity_series, \n",
    "            session_distinctiveness_series, session_session_similarity_dataframe,\n",
    "            session_std_series, presentation_raw_deviation_series, presentation_std_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a2a95604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jdv223\\AppData\\Local\\Temp\\ipykernel_44664\\2182494715.py:101: RuntimeWarning: Mean of empty slice\n",
      "  presentation_session_fits = np.nanmean(session_i_to_j_similarities_no_diag, axis=1)\n"
     ]
    }
   ],
   "source": [
    "presentation_session_fit_series, session_average_similarity_series, session_distinctiveness_series, df_session_session_similarity, session_std_series, presentation_raw_deviation_series, presentation_std_series = calculate_placement_metrics(\n",
    "    df_presentations=df_all_no_embeddings,\n",
    "    df_sessions=df_sessions,\n",
    "    pres_similarities_matrix=similarity_matrix,\n",
    "    session_column_name=session_column_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8aacabe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the series to the DataFrames\n",
    "df_all_no_embeddings['Presentation Session Fit'] = presentation_session_fit_series.reindex(df_all_no_embeddings.index)\n",
    "df_all_no_embeddings['Presentation Raw Deviation'] = presentation_raw_deviation_series.reindex(df_all_no_embeddings.index)\n",
    "df_all_no_embeddings['Presentation Standardized Deviation'] = presentation_std_series.reindex(df_all_no_embeddings.index)\n",
    "\n",
    "# Align the index of session_average_similarity_series to match the 'Session Name' column in df_sessions\n",
    "if 'Session Name' in df_sessions.columns:\n",
    "    df_sessions['Session Coherence'] = df_sessions['Session Name'].map(session_average_similarity_series)\n",
    "    df_sessions['Session Std Dev'] = df_sessions['Session Name'].map(session_std_series)\n",
    "else:\n",
    "    df_sessions['Session Coherence'] = session_average_similarity_series.reindex(df_sessions.index)\n",
    "    df_sessions['Session Std Dev'] = session_std_series.reindex(df_sessions.index)\n",
    "df_sessions['Session Distinctiveness'] = session_distinctiveness_series.reindex(df_sessions.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a10a9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'presentation_session_fit', # remove repetitive topic column\n",
    "]\n",
    "df_all_no_embeddings = df_all_no_embeddings.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "columns_to_drop = [\n",
    "    'session_coherence', # remove repetitive topic column\n",
    "    'session_distinctiveness', # remove repetitive topic column\n",
    "]\n",
    "df_sessions = df_sessions.drop(columns_to_drop, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "27e52568",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'topic', # remove repetitive topic column\n",
    "]\n",
    "df_all_no_embeddings = df_all_no_embeddings.drop(columns_to_drop, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf49947",
   "metadata": {},
   "source": [
    "## Create Encrypted Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3264f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'Abstract',\n",
    "    'Title and Abstract',\n",
    "]\n",
    "df_no_abstract = df_all_no_embeddings.drop(columns_to_drop, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5d26cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables\n",
    "load_dotenv(\".env\")\n",
    "if \"DATAFRAME_PW\" not in os.environ:\n",
    "    raise ValueError(\n",
    "        \"Dataframe Encryption Password must be in environmental variables. DATAFRAME_PW not found in environment variables. Please set it in your .env file.\"\n",
    "    )\n",
    "else:\n",
    "    password_df = os.environ[\"DATAFRAME_PW\"]\n",
    "filename_enc_df = 'encrypted_df.crypt'\n",
    "# Create an encrypted dataframe for publishing.\n",
    "import cryptpandas as crp\n",
    "\n",
    "# Ensure '7 digit ID' and 'Start time' are string type to avoid ArrowInvalid errors\n",
    "columns_to_string = ['7 digit ID', 'Start time']\n",
    "for col in columns_to_string:\n",
    "    if col in df_all_no_embeddings.columns:\n",
    "        df_all_no_embeddings[col] = df_all_no_embeddings[col].astype(str)\n",
    "\n",
    "# Encrypt the DataFrame and save as a pickle\n",
    "crp.to_encrypted(df_all_no_embeddings, password=password_df, path=filename_enc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f2600bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure '7 digit ID' and 'Start time' are string type to avoid ArrowInvalid errors\n",
    "columns_to_string = ['7 digit ID', 'Start time']\n",
    "for col in columns_to_string:\n",
    "    if col in df_no_abstract.columns:\n",
    "        df_no_abstract[col] = df_no_abstract[col].astype(str)\n",
    "\n",
    "# Save the abstract-free DataFrame without encryption\n",
    "df_no_abstract.to_parquet('df_no_abstractAIM25.parquet', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "05c4b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Sessions Dataframe\n",
    "df_sessions.to_parquet('df_sessionsAIM25.parquet', compression='snappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b174707",
   "metadata": {},
   "source": [
    "### Save the similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "47ae2cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Similarity matrices saved as Parquet files\n"
     ]
    }
   ],
   "source": [
    "pres_similarities_df = pd.DataFrame(similarity_matrix, \n",
    "                                    index=df_all_embeddings.index, \n",
    "                                    columns=df_all_embeddings.index)\n",
    "# Save presentation similarities matrix\n",
    "pres_similarities_df.to_parquet('pres_similarities_matrixAIM25.parquet', compression='snappy')\n",
    "\n",
    "# Save the session similiarities matrix DataFrame\n",
    "df_session_session_similarity.to_parquet('session_similarities_matrixAIM25.parquet', compression='snappy')\n",
    "\n",
    "print(\"✓ Similarity matrices saved as Parquet files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca718db",
   "metadata": {},
   "source": [
    "### Match Committees to Related Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66cfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the committee file from CSV/Excel with flexible column selection\n",
    "committee_file_path = 'ASABE Committees.csv'  # Update this path as needed (can also use .xlsx)\n",
    "\n",
    "# Load committees\n",
    "df_committees, committee_name_column, description_column, combined_column = session_organizer.load_committees(\n",
    "    committee_file_path,\n",
    "    Committee_Name_column='Committee_Name',  # Actual column name in your file\n",
    "    Description_column='Description',        # Actual column name in your file\n",
    "    committee_name_column='Committee_Name',  # Desired output column name\n",
    "    description_column='Description',        # Desired output column name\n",
    "    combined_column='Name_Description'       # Combined column for embeddings\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(df_committees)} committees\")\n",
    "print(f\"Committee name column: {committee_name_column}\")\n",
    "print(f\"Description column: {description_column}\")\n",
    "print(f\"Combined column: {combined_column}\")\n",
    "print(\"\\nFirst few committees:\")\n",
    "print(df_committees[[committee_name_column, description_column]].head())\n",
    "\n",
    "# Generate embeddings for committees using the combined column\n",
    "df_committee_embeddings = embed_with_resume(df_committees, combined_column, 'gemini-embedding-exp-03-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most similar committees for each session\n",
    "session_committee_matches = session_organizer.find_most_similar_committees_by_presentations(\n",
    "    df_sessions, \n",
    "    df_all_embeddings, \n",
    "    df_committees, \n",
    "    df_committee_embeddings, \n",
    "    top_n=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f790efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions = session_organizer.add_committee_matches_to_clusters(df_sessions, session_committee_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5384dab3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_embeddings_from_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_embeddings_main = \u001b[43mload_embeddings_from_file\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33membeddings_final_presentations_25_main.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'load_embeddings_from_file' is not defined"
     ]
    }
   ],
   "source": [
    "df_embeddings_main = load_embeddings_from_file(\"embeddings_final_presentations_25_main.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_sort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
